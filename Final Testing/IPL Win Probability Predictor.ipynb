{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_excel('matches.xlsx')\n",
    "deliveries = pd.read_excel('deliveries.xlsx')\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape,deliveries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the 1st innings,2nd innings score in a particular matchid\n",
    "# lets say match id = 1,so inning 1 score = 207,inning 2 score = 172,in that way\n",
    "\n",
    "totalrun_df = deliveries.groupby(['Match_id','Inning Number']).sum()['Total'].reset_index()\n",
    "totalrun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing only the first innings,as we will be predicting for the second innnigs\n",
    "\n",
    "totalrun_df = totalrun_df[totalrun_df['Inning Number']==1]\n",
    "totalrun_df['Total'] = totalrun_df['Total'].apply(lambda x:x+1)\n",
    "totalrun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Merging the total first innings score df with the matches df,\n",
    "where left side merging is done on \"id\" column of the matches\n",
    "and right side merging is done on \"match_id\" column of the totalrun_df\n",
    "\n",
    "This is an inner join. The inner join returns only the rows that have matching values in both tables, \n",
    "in this case, the 'matches' DataFrame and the 'totalrun_df' DataFrame. \n",
    "It returns only the rows where the 'id' column in the \"matches\" DataFrame has a match in the 'match_id' \n",
    "column of the \"totalrun_df\" DataFrame.\n",
    "\n",
    "'''\n",
    "\n",
    "match_df = matches.merge(totalrun_df[['Match_id','Total']],\n",
    "                       left_on='id',right_on='Match_id')\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['team1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\n",
    "    'Sunrisers Hyderabad',\n",
    "    'Mumbai Indians',\n",
    "    'Royal Challengers Bangalore',\n",
    "    'Kolkata Knight Riders',\n",
    "    'Kings XI Punjab',\n",
    "    'Chennai Super Kings',\n",
    "    'Rajasthan Royals',\n",
    "    'Delhi Capitals',\n",
    "    'Rising Pune Supergiant',\n",
    "    'Gujarat Lions',\n",
    "    'Delhi Daredevils',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the Delhi Daredevils with Delhi Capitals\n",
    "\n",
    "match_df['team1'] = match_df['team1'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "match_df['team2'] = match_df['team2'].str.replace('Delhi Daredevils','Delhi Capitals')\n",
    "\n",
    "\n",
    "# replacing the Deccan Chargers with Sunrises Hyderabad\n",
    "\n",
    "match_df['team1'] = match_df['team1'].str.replace('Deccan Chargers','Sunrisers Hyderabad')\n",
    "match_df['team2'] = match_df['team2'].str.replace('Deccan Chargers','Sunrisers Hyderabad')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will consider only frequently occuring teams,\n",
    "# which are mentioned in the teams list\n",
    "\n",
    "match_df = match_df[match_df['team1'].isin(teams)]\n",
    "match_df = match_df[match_df['team2'].isin(teams)]\n",
    "\n",
    "match_df['team1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliveries.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging matchdf with delevieries on match_id\n",
    "\n",
    "delivery_df = match_df.merge(deliveries,on='Match_id')\n",
    "\n",
    "delivery_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering the 2nd innings because we have to keep a check on the current score of second innings\n",
    "\n",
    "delivery_df = delivery_df[delivery_df['Inning Number'] == 2]\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# current score of particular match\n",
    "\n",
    "delivery_df['current_score'] = delivery_df.groupby('Match_id')['Total_y'].cumsum()\n",
    "\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs left \n",
    "\n",
    "delivery_df['runs_left'] = delivery_df['Total_x']-delivery_df['current_score']\n",
    "\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if one ball is played,then balls left = 120-1 = 119\n",
    "if two balls are played,then balls left = 120-2 = 118\n",
    "\n",
    "so similarly if over=1,over has 6 balls right,so 1*6 = 6\n",
    "now,ball = 1,so 6+1 = 7,now 126-7 = 119,which is same as (1)\n",
    "\n",
    "so we'll use balls_left = 126-(over*6+current_ball)\n",
    "\n",
    "'''\n",
    "\n",
    "# balls left\n",
    "\n",
    "\n",
    "delivery_df['balls_left'] = 120-(delivery_df['Over']*6+delivery_df['Ball'])\n",
    "\n",
    "delivery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(delivery_df['player_dismissed'].unique())[:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# filling nan values with \"0\"\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].fillna(\"0\")\n",
    "\n",
    "# now we will convert this player_dismissed col into a boolean col\n",
    "# if the player is not dismissed then it's 0 else its 1\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].apply(lambda x:x if x==\"0\" else \"1\")\n",
    "\n",
    "# converting string to int\n",
    "\n",
    "delivery_df['player_dismissed'] = delivery_df['player_dismissed'].astype('int')\n",
    "\n",
    "\n",
    "delivery_df['player_dismissed'].unique()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wickets left\n",
    "\n",
    "wickets = delivery_df.groupby('Match_id')['player_dismissed'].cumsum().values\n",
    "\n",
    "delivery_df['wickets_left'] = 10-wickets\n",
    "\n",
    "delivery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current run rate\n",
    "# It is a common practice to express run rates in cricket as runs per over, so the score is multiplied by 6.\n",
    "\n",
    "\n",
    "delivery_df['cur_run_rate'] = (delivery_df['current_score']*6)/(120-delivery_df['balls_left']) \n",
    "\n",
    "# required run rate\n",
    "\n",
    "delivery_df['req_run_rate'] = (delivery_df['runs_left']*6)/(delivery_df['balls_left'])\n",
    "\n",
    "\n",
    "delivery_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultfun(row):\n",
    "    return 1 if row['Batting_team'] == row['winner'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_df['result'] = delivery_df.apply(resultfun,axis=1)\n",
    "delivery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.countplot(delivery_df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = delivery_df[['Batting_team','Bowling_team','city','runs_left',\n",
    "                        'balls_left','wickets_left','Total_x','cur_run_rate',\n",
    "                        'req_run_rate','Predicted_total_run_batter','result']]\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping of null values\n",
    "\n",
    "\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['runs_left', 'balls_left', 'wickets_left', 'Total_x',\n",
    "    'cur_run_rate', 'req_run_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df['balls_left'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df.to_excel(\"final_data.xlsx\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Batting_team         Bowling_team       city  runs_left  \\\n0  Royal Challengers Bangalore  Sunrisers Hyderabad  Hyderabad        207   \n1  Royal Challengers Bangalore  Sunrisers Hyderabad  Hyderabad        207   \n2  Royal Challengers Bangalore  Sunrisers Hyderabad  Hyderabad        207   \n3  Royal Challengers Bangalore  Sunrisers Hyderabad  Hyderabad        205   \n4  Royal Challengers Bangalore  Sunrisers Hyderabad  Hyderabad        201   \n\n   balls_left  wickets_left  Total_x  cur_run_rate  req_run_rate  \\\n0         119            10      208           6.0     10.436975   \n1         118            10      208           3.0     10.525424   \n2         117            10      208           2.0     10.615385   \n3         116            10      208           4.5     10.603448   \n4         115            10      208           8.4     10.486957   \n\n   Predicted_total_run_batter  result  \n0                   54.775223       0  \n1                   30.693213       0  \n2                   30.729660       0  \n3                   30.766109       0  \n4                   30.802555       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Batting_team</th>\n      <th>Bowling_team</th>\n      <th>city</th>\n      <th>runs_left</th>\n      <th>balls_left</th>\n      <th>wickets_left</th>\n      <th>Total_x</th>\n      <th>cur_run_rate</th>\n      <th>req_run_rate</th>\n      <th>Predicted_total_run_batter</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Royal Challengers Bangalore</td>\n      <td>Sunrisers Hyderabad</td>\n      <td>Hyderabad</td>\n      <td>207</td>\n      <td>119</td>\n      <td>10</td>\n      <td>208</td>\n      <td>6.0</td>\n      <td>10.436975</td>\n      <td>54.775223</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Royal Challengers Bangalore</td>\n      <td>Sunrisers Hyderabad</td>\n      <td>Hyderabad</td>\n      <td>207</td>\n      <td>118</td>\n      <td>10</td>\n      <td>208</td>\n      <td>3.0</td>\n      <td>10.525424</td>\n      <td>30.693213</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Royal Challengers Bangalore</td>\n      <td>Sunrisers Hyderabad</td>\n      <td>Hyderabad</td>\n      <td>207</td>\n      <td>117</td>\n      <td>10</td>\n      <td>208</td>\n      <td>2.0</td>\n      <td>10.615385</td>\n      <td>30.729660</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Royal Challengers Bangalore</td>\n      <td>Sunrisers Hyderabad</td>\n      <td>Hyderabad</td>\n      <td>205</td>\n      <td>116</td>\n      <td>10</td>\n      <td>208</td>\n      <td>4.5</td>\n      <td>10.603448</td>\n      <td>30.766109</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Royal Challengers Bangalore</td>\n      <td>Sunrisers Hyderabad</td>\n      <td>Hyderabad</td>\n      <td>201</td>\n      <td>115</td>\n      <td>10</td>\n      <td>208</td>\n      <td>8.4</td>\n      <td>10.486957</td>\n      <td>30.802555</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "final_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:29:12.111341900Z",
     "start_time": "2023-10-18T11:28:58.282764400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T11:29:16.689216900Z",
     "start_time": "2023-10-18T11:29:16.563316800Z"
    }
   },
   "outputs": [],
   "source": [
    "data = final_df.copy()\n",
    "\n",
    "test = data['result']\n",
    "# \n",
    "train = data.drop(['result'],axis = 1)\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "train['cur_run_rate'] = train['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# train['Batting_team'].unique()\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483358847876623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     42113\n",
      "           1       0.95      0.95      0.95     46072\n",
      "\n",
      "    accuracy                           0.95     88185\n",
      "   macro avg       0.95      0.95      0.95     88185\n",
      "weighted avg       0.95      0.95      0.95     88185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = train\n",
    "y = test\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Create and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=45)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print a classification report for more detailed performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:29:22.740643900Z",
     "start_time": "2023-10-18T11:29:18.532785900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7906298600311042\n",
      "Test Accuracy: 0.7869535334180326\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76      9832\n",
      "           1       0.76      0.87      0.81     10744\n",
      "\n",
      "    accuracy                           0.79     20576\n",
      "   macro avg       0.80      0.79      0.79     20576\n",
      "weighted avg       0.80      0.79      0.79     20576\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76     22861\n",
      "           1       0.76      0.87      0.81     25152\n",
      "\n",
      "    accuracy                           0.79     48013\n",
      "   macro avg       0.79      0.78      0.78     48013\n",
      "weighted avg       0.79      0.79      0.78     48013\n",
      "Validation Accuracy: 0.8403479782270606\n",
      "Test Accuracy: 0.8418761585403953\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      9832\n",
      "           1       0.84      0.86      0.85     10744\n",
      "\n",
      "    accuracy                           0.84     20576\n",
      "   macro avg       0.84      0.84      0.84     20576\n",
      "weighted avg       0.84      0.84      0.84     20576\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83     22861\n",
      "           1       0.84      0.86      0.85     25152\n",
      "\n",
      "    accuracy                           0.84     48013\n",
      "   macro avg       0.84      0.84      0.84     48013\n",
      "weighted avg       0.84      0.84      0.84     48013\n",
      "Validation Accuracy: 0.9104782270606532\n",
      "Test Accuracy: 0.9101701622477246\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      9832\n",
      "           1       0.90      0.93      0.92     10744\n",
      "\n",
      "    accuracy                           0.91     20576\n",
      "   macro avg       0.91      0.91      0.91     20576\n",
      "weighted avg       0.91      0.91      0.91     20576\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90     22861\n",
      "           1       0.91      0.93      0.92     25152\n",
      "\n",
      "    accuracy                           0.91     48013\n",
      "   macro avg       0.91      0.91      0.91     48013\n",
      "weighted avg       0.91      0.91      0.91     48013\n",
      "Validation Accuracy: 0.9562111197511665\n",
      "Test Accuracy: 0.9576364734551059\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      9832\n",
      "           1       0.95      0.96      0.96     10744\n",
      "\n",
      "    accuracy                           0.96     20576\n",
      "   macro avg       0.96      0.96      0.96     20576\n",
      "weighted avg       0.96      0.96      0.96     20576\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     22861\n",
      "           1       0.96      0.96      0.96     25152\n",
      "\n",
      "    accuracy                           0.96     48013\n",
      "   macro avg       0.96      0.96      0.96     48013\n",
      "weighted avg       0.96      0.96      0.96     48013\n",
      "Validation Accuracy: 0.978907465007776\n",
      "Test Accuracy: 0.9787140982650532\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      9832\n",
      "           1       0.99      0.97      0.98     10744\n",
      "\n",
      "    accuracy                           0.98     20576\n",
      "   macro avg       0.98      0.98      0.98     20576\n",
      "weighted avg       0.98      0.98      0.98     20576\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     22861\n",
      "           1       0.99      0.97      0.98     25152\n",
      "\n",
      "    accuracy                           0.98     48013\n",
      "   macro avg       0.98      0.98      0.98     48013\n",
      "weighted avg       0.98      0.98      0.98     48013\n",
      "\n",
      "    0         1         2\n",
      "0   5  0.790630  0.786954\n",
      "1  10  0.840348  0.841876\n",
      "2  15  0.910478  0.910170\n",
      "3  20  0.956211  0.957636\n",
      "4  50  0.978907  0.978714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = train  # Assuming train contains your feature data\n",
    "y = test   # Assuming test contains your target data\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Perform Train-Validation-Test Split\n",
    "# First, split the data into training and the rest (combined validation and test)\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# Then, split the rest into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.7, random_state=42)\n",
    "depth = [5,10,15,20,50]\n",
    "res = []\n",
    "for dpt in depth:\n",
    "    \n",
    "    # Create and train the RandomForestClassifier on the training set\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=45, max_depth=dpt)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    \n",
    "    # Evaluate the classifier's performance on the validation set\n",
    "    validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(\"Validation Accuracy:\", validation_accuracy)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the classifier's performance on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    # You can also print classification reports for more detailed performance metrics\n",
    "    print(\"Validation Classification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    print(\"Test Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    rn = [dpt, validation_accuracy, test_accuracy]\n",
    "    res.append(rn)\n",
    "res_df = pd.DataFrame.from_records(res)  \n",
    "print(res_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T11:29:40.664833800Z",
     "start_time": "2023-10-18T11:29:36.962344600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = train  # Assuming train contains your feature data\n",
    "y = test   # Assuming test contains your target data\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "ts_size = [0.2,0.3,0.4,0.5]\n",
    "qwe= []\n",
    "for asd in ts_size:    \n",
    "    # Perform Train-Validation-Test Split\n",
    "    # First, split the data into training and the rest (combined validation and test)\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=asd, random_state=42)\n",
    "    \n",
    "    # Then, split the rest into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=asd, random_state=42)\n",
    "    \n",
    "    # Create and train the Gaussian Naive Bayes classifier on the training set\n",
    "    clf_nb = GaussianNB()\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set for Naive Bayes\n",
    "    y_val_pred_nb = clf_nb.predict(X_val)\n",
    "    \n",
    "    # Evaluate the classifier's performance on the validation set for Naive Bayes\n",
    "    validation_accuracy_nb = accuracy_score(y_val, y_val_pred_nb)\n",
    "    \n",
    "    # Make predictions on the test set for Naive Bayes\n",
    "    y_test_pred_nb = clf_nb.predict(X_test)\n",
    "    \n",
    "    # Evaluate the classifier's performance on the test set for Naive Bayes\n",
    "    test_accuracy_nb = accuracy_score(y_test, y_test_pred_nb)\n",
    "    \n",
    "    # Print validation and test accuracy\n",
    "    print(\"Validation Accuracy (Naive Bayes):\", validation_accuracy_nb)\n",
    "    print(\"Test Accuracy (Naive Bayes):\", test_accuracy_nb)\n",
    "    \n",
    "    # You can also print classification reports for more detailed performance metrics\n",
    "    print(\"Validation Classification Report (Naive Bayes):\")\n",
    "    print(classification_report(y_val, y_val_pred_nb))\n",
    "    \n",
    "    print(\"Test Classification Report (Naive Bayes):\")\n",
    "    print(classification_report(y_test, y_test_pred_nb))\n",
    "    \n",
    "    rn = [asd, validation_accuracy_nb, test_accuracy_nb]\n",
    "    qwe.append(rn)\n",
    "res_df = pd.DataFrame.from_records(qwe)  \n",
    "print(res_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "# data = final_df.copy()\n",
    "# print(data)\n",
    "# train_target = data['result']\n",
    "# train_features = data.drop(['result'],axis = 1)\n",
    "# # Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "# train_features['cur_run_rate'] = train_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "# \n",
    "# testing_df = pd.read_excel(\"testing_data.xlsx\")\n",
    "# validation_data = testing_df.copy()\n",
    "# \n",
    "# validate_target = validation_data['result']\n",
    "# validate_features = validation_data.drop(['result'],axis = 1)\n",
    "# # Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "# validate_features['cur_run_rate'] = validate_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the training data\n",
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "data = final_df.copy()\n",
    "\n",
    "# Extract features and target for training data\n",
    "train_target = data['result']\n",
    "train_features = data.drop(['result'], axis=1)\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "train_features['cur_run_rate'] = train_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Load the validation data\n",
    "testing_df = pd.read_excel(\"testing_data.xlsx\")\n",
    "validation_data = testing_df.copy()\n",
    "\n",
    "# Extract features and target for validation data\n",
    "validate_target = validation_data['result']\n",
    "validate_features = validation_data.drop(['result'], axis=1)\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros for validation data\n",
    "validate_features['cur_run_rate'] = validate_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Combine the training and validation data for consistent label encoding\n",
    "combined_data = pd.concat([train_features, validate_features], axis=0)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    combined_data[col] = label_encoders[col].fit_transform(combined_data[col])\n",
    "\n",
    "# Split the combined data back into training and validation\n",
    "X1 = combined_data[:len(train_features)]\n",
    "X2 = combined_data[len(train_features):]\n",
    "\n",
    "# Create and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=45)\n",
    "clf.fit(X1, train_target)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validate_pred = clf.predict(X2)\n",
    "\n",
    "# Evaluate the classifier's performance on the validation set\n",
    "accuracy = accuracy_score(validate_target, validate_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print a classification report for more detailed performance metrics\n",
    "print(classification_report(validate_target, validate_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the training data\n",
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "data = final_df.copy()\n",
    "\n",
    "# Extract features and target for training data\n",
    "train_target = data['result']\n",
    "train_features = data.drop(['result'], axis=1)\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "train_features['cur_run_rate'] = train_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Load the validation data\n",
    "testing_df = pd.read_excel(\"testing_data.xlsx\")\n",
    "validation_data = testing_df.copy()\n",
    "\n",
    "# Extract features and target for validation data\n",
    "validate_target = validation_data['result']\n",
    "validate_features = validation_data.drop(['result'], axis=1)\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros for validation data\n",
    "validate_features['cur_run_rate'] = validate_features['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Combine the training and validation data for consistent label encoding\n",
    "combined_data = pd.concat([train_features, validate_features], axis=0)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    combined_data[col] = label_encoders[col].fit_transform(combined_data[col])\n",
    "\n",
    "# Split the combined data back into training and validation\n",
    "X1 = combined_data[:len(train_features)]\n",
    "X2 = combined_data[len(train_features):]\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create and train the RandomForestClassifier with GridSearchCV\n",
    "clf = RandomForestClassifier(random_state=45)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X1, train_target)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Make predictions on the validation set using the best model\n",
    "best_clf = grid_search.best_estimator_\n",
    "validate_pred = best_clf.predict(X2)\n",
    "\n",
    "# Evaluate the classifier's performance on the validation set\n",
    "accuracy = accuracy_score(validate_target, validate_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print a classification report for more detailed performance metrics\n",
    "print(classification_report(validate_target, validate_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a confusion matrix to visualize true positives, true negatives, false positives, and false negatives\n",
    "conf_matrix = confusion_matrix(validate_target, validate_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Lost', 'Won'], yticklabels=['Lost', 'Won'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importances using the best classifier\n",
    "if isinstance(best_clf, RandomForestClassifier):\n",
    "    feature_importances = best_clf.feature_importances_\n",
    "    feature_names = train_features.columns\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    sorted_idx = feature_importances.argsort()[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(train_features.shape[1]), feature_importances[sorted_idx], align='center')\n",
    "    plt.xticks(range(train_features.shape[1]), feature_names[sorted_idx], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# # Load the data\n",
    "# final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "# \n",
    "# # Extract features and target\n",
    "# X = final_df.drop(['result'], axis=1)\n",
    "# y = final_df['result']\n",
    "# \n",
    "# # Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "# X['cur_run_rate'] = X['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "# \n",
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "# \n",
    "# for col in categorical_columns:\n",
    "#     label_encoders[col] = LabelEncoder()\n",
    "#     X[col] = label_encoders[col].fit_transform(X[col])\n",
    "# \n",
    "# # Split the data into training and validation\n",
    "# X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "# \n",
    "# # Define the parameter grid with the specified hyperparameters\n",
    "# param_grid = {\n",
    "#     'n_estimators': [200],  # Set to 200\n",
    "#     'max_depth': [10],  # Set to 10\n",
    "#     'min_samples_split': [2],  # Set to 2\n",
    "#     'min_samples_leaf': [2]  # Set to 2\n",
    "# }\n",
    "# \n",
    "# # Create and train the RandomForestClassifier with GridSearchCV\n",
    "# clf = RandomForestClassifier(random_state=45)\n",
    "# grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# \n",
    "# # Get the best parameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# \n",
    "# # Make predictions on the validation set using the best model\n",
    "# best_clf = grid_search.best_estimator_\n",
    "# validate_pred = best_clf.predict(X_validate)\n",
    "# \n",
    "# # Evaluate the classifier's performance on the validation set\n",
    "# accuracy = accuracy_score(y_validate, validate_pred)\n",
    "# print(\"Validation Accuracy:\", accuracy)\n",
    "# \n",
    "# # You can also print a classification report for more detailed performance metrics\n",
    "# print(classification_report(y_validate, validate_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "\n",
    "# Extract features and target\n",
    "X = final_df.drop(['result'], axis=1)\n",
    "y = final_df['result']\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "X['cur_run_rate'] = X['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and testing (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=45)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=45)\n",
    "\n",
    "# Create and train the RandomForestClassifier with your specified hyperparameters\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=2, min_samples_leaf=2, random_state=45)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validate_pred = clf.predict(X_validate)\n",
    "\n",
    "# Evaluate the classifier's performance on the validation set\n",
    "validate_accuracy = accuracy_score(y_validate, validate_pred)\n",
    "print(\"Validation Accuracy:\", validate_accuracy)\n",
    "\n",
    "# Print a classification report for the validation set\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_validate, validate_pred))\n",
    "\n",
    "# Make predictions on the testing set\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance on the testing set\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Print a classification report for the testing set\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, test_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "logistic_reg = LogisticRegression(random_state=45)\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validate_pred_lr = logistic_reg.predict(X_validate)\n",
    "\n",
    "# Evaluate the classifier's performance on the validation set\n",
    "validate_accuracy_lr = accuracy_score(y_validate, validate_pred_lr)\n",
    "print(\"Logistic Regression Validation Accuracy:\", validate_accuracy_lr)\n",
    "\n",
    "# Print a classification report for the validation set\n",
    "print(\"Logistic Regression Validation Classification Report:\")\n",
    "print(classification_report(y_validate, validate_pred_lr))\n",
    "\n",
    "# Make predictions on the testing set\n",
    "test_pred_lr = logistic_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance on the testing set\n",
    "test_accuracy_lr = accuracy_score(y_test, test_pred_lr)\n",
    "print(\"Logistic Regression Testing Accuracy:\", test_accuracy_lr)\n",
    "\n",
    "# Print a classification report for the testing set\n",
    "print(\"Logistic Regression Testing Classification Report:\")\n",
    "print(classification_report(y_test, test_pred_lr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the Support Vector Machine (SVM) model\n",
    "svm_classifier = SVC(kernel='linear', random_state=45)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "validate_pred_svm = svm_classifier.predict(X_validate)\n",
    "\n",
    "# Evaluate the classifier's performance on the validation set\n",
    "validate_accuracy_svm = accuracy_score(y_validate, validate_pred_svm)\n",
    "print(\"SVM Validation Accuracy:\", validate_accuracy_svm)\n",
    "\n",
    "# Print a classification report for the validation set\n",
    "print(\"SVM Validation Classification Report:\")\n",
    "print(classification_report(y_validate, validate_pred_svm))\n",
    "\n",
    "# Make predictions on the testing set\n",
    "test_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance on the testing set\n",
    "test_accuracy_svm = accuracy_score(y_test, test_pred_svm)\n",
    "print(\"SVM Testing Accuracy:\", test_accuracy_svm)\n",
    "\n",
    "# Print a classification report for the testing set\n",
    "print(\"SVM Testing Classification Report:\")\n",
    "print(classification_report(y_test, test_pred_svm))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "\n",
    "# Extract features and target\n",
    "X = final_df.drop(['result'], axis=1)\n",
    "y = final_df['result']\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "X['cur_run_rate'] = X['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and testing (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=45)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=45)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create and train the RandomForestClassifier with GridSearchCV\n",
    "clf = RandomForestClassifier(random_state=45)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Make predictions on the validation set using the best model\n",
    "best_clf = grid_search.best_estimator_\n",
    "validate_pred = best_clf.predict(X_validate)\n",
    "\n",
    "# Calculate and print the validation accuracy\n",
    "accuracy_validate = accuracy_score(y_validate, validate_pred)\n",
    "print(\"Validation Accuracy:\", accuracy_validate)\n",
    "\n",
    "# You can also print a classification report for more detailed performance metrics\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_validate, validate_pred))\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "test_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "accuracy_test = accuracy_score(y_test, test_pred)\n",
    "print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "# You can also print a classification report for more detailed performance metrics\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Calculate AUC-ROC and plot the curve\n",
    "test_pred_probs = best_clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_pred_probs)\n",
    "roc_auc = roc_auc_score(y_test, test_pred_probs)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejka\\AppData\\Local\\Temp\\ipykernel_10720\\739792909.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, current_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0              0.90379       0.901211  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "5          100        10                 5                4   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "5             0.897734       0.898285  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "5          100        10                 5                4   \n",
      "6          100        10                10                1   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "5             0.897734       0.898285  \n",
      "6             0.899367       0.896448  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "5          100        10                 5                4   \n",
      "6          100        10                10                1   \n",
      "7          100        10                10                2   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "5             0.897734       0.898285  \n",
      "6             0.899367       0.896448  \n",
      "7             0.899367       0.896108  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "5          100        10                 5                4   \n",
      "6          100        10                10                1   \n",
      "7          100        10                10                2   \n",
      "8          100        10                10                4   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "5             0.897734       0.898285  \n",
      "6             0.899367       0.896448  \n",
      "7             0.899367       0.896108  \n",
      "8             0.900388       0.897197  \n",
      "  n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0          100        10                 2                1   \n",
      "1          100        10                 2                2   \n",
      "2          100        10                 2                4   \n",
      "3          100        10                 5                1   \n",
      "4          100        10                 5                2   \n",
      "5          100        10                 5                4   \n",
      "6          100        10                10                1   \n",
      "7          100        10                10                2   \n",
      "8          100        10                10                4   \n",
      "9          200        10                 2                1   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.903790       0.901211  \n",
      "1             0.899231       0.896653  \n",
      "2             0.897734       0.898285  \n",
      "3             0.899231       0.896380  \n",
      "4             0.898415       0.897469  \n",
      "5             0.897734       0.898285  \n",
      "6             0.899367       0.896448  \n",
      "7             0.899367       0.896108  \n",
      "8             0.900388       0.897197  \n",
      "9             0.903586       0.901891  \n",
      "   n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0           100        10                 2                1   \n",
      "1           100        10                 2                2   \n",
      "2           100        10                 2                4   \n",
      "3           100        10                 5                1   \n",
      "4           100        10                 5                2   \n",
      "5           100        10                 5                4   \n",
      "6           100        10                10                1   \n",
      "7           100        10                10                2   \n",
      "8           100        10                10                4   \n",
      "9           200        10                 2                1   \n",
      "10          200        10                 2                2   \n",
      "\n",
      "    Validation Accuracy  Test Accuracy  \n",
      "0              0.903790       0.901211  \n",
      "1              0.899231       0.896653  \n",
      "2              0.897734       0.898285  \n",
      "3              0.899231       0.896380  \n",
      "4              0.898415       0.897469  \n",
      "5              0.897734       0.898285  \n",
      "6              0.899367       0.896448  \n",
      "7              0.899367       0.896108  \n",
      "8              0.900388       0.897197  \n",
      "9              0.903586       0.901891  \n",
      "10             0.899775       0.898217  \n",
      "   n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0           100        10                 2                1   \n",
      "1           100        10                 2                2   \n",
      "2           100        10                 2                4   \n",
      "3           100        10                 5                1   \n",
      "4           100        10                 5                2   \n",
      "5           100        10                 5                4   \n",
      "6           100        10                10                1   \n",
      "7           100        10                10                2   \n",
      "8           100        10                10                4   \n",
      "9           200        10                 2                1   \n",
      "10          200        10                 2                2   \n",
      "11          200        10                 2                4   \n",
      "\n",
      "    Validation Accuracy  Test Accuracy  \n",
      "0              0.903790       0.901211  \n",
      "1              0.899231       0.896653  \n",
      "2              0.897734       0.898285  \n",
      "3              0.899231       0.896380  \n",
      "4              0.898415       0.897469  \n",
      "5              0.897734       0.898285  \n",
      "6              0.899367       0.896448  \n",
      "7              0.899367       0.896108  \n",
      "8              0.900388       0.897197  \n",
      "9              0.903586       0.901891  \n",
      "10             0.899775       0.898217  \n",
      "11             0.900456       0.899170  \n",
      "   n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0           100        10                 2                1   \n",
      "1           100        10                 2                2   \n",
      "2           100        10                 2                4   \n",
      "3           100        10                 5                1   \n",
      "4           100        10                 5                2   \n",
      "5           100        10                 5                4   \n",
      "6           100        10                10                1   \n",
      "7           100        10                10                2   \n",
      "8           100        10                10                4   \n",
      "9           200        10                 2                1   \n",
      "10          200        10                 2                2   \n",
      "11          200        10                 2                4   \n",
      "12          200        10                 5                1   \n",
      "\n",
      "    Validation Accuracy  Test Accuracy  \n",
      "0              0.903790       0.901211  \n",
      "1              0.899231       0.896653  \n",
      "2              0.897734       0.898285  \n",
      "3              0.899231       0.896380  \n",
      "4              0.898415       0.897469  \n",
      "5              0.897734       0.898285  \n",
      "6              0.899367       0.896448  \n",
      "7              0.899367       0.896108  \n",
      "8              0.900388       0.897197  \n",
      "9              0.903586       0.901891  \n",
      "10             0.899775       0.898217  \n",
      "11             0.900456       0.899170  \n",
      "12             0.903518       0.900191  \n",
      "   n_estimators max_depth min_samples_split min_samples_leaf  \\\n",
      "0           100        10                 2                1   \n",
      "1           100        10                 2                2   \n",
      "2           100        10                 2                4   \n",
      "3           100        10                 5                1   \n",
      "4           100        10                 5                2   \n",
      "5           100        10                 5                4   \n",
      "6           100        10                10                1   \n",
      "7           100        10                10                2   \n",
      "8           100        10                10                4   \n",
      "9           200        10                 2                1   \n",
      "10          200        10                 2                2   \n",
      "11          200        10                 2                4   \n",
      "12          200        10                 5                1   \n",
      "13          200        10                 5                2   \n",
      "\n",
      "    Validation Accuracy  Test Accuracy  \n",
      "0              0.903790       0.901211  \n",
      "1              0.899231       0.896653  \n",
      "2              0.897734       0.898285  \n",
      "3              0.899231       0.896380  \n",
      "4              0.898415       0.897469  \n",
      "5              0.897734       0.898285  \n",
      "6              0.899367       0.896448  \n",
      "7              0.899367       0.896108  \n",
      "8              0.900388       0.897197  \n",
      "9              0.903586       0.901891  \n",
      "10             0.899775       0.898217  \n",
      "11             0.900456       0.899170  \n",
      "12             0.903518       0.900191  \n",
      "13             0.901681       0.899238  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "final_df = pd.read_excel(\"final_data.xlsx\")\n",
    "\n",
    "# Extract features and target\n",
    "X = final_df.drop(['result'], axis=1)\n",
    "y = final_df['result']\n",
    "\n",
    "# Replace inf and negative values in 'cur_run_rate' with zeros\n",
    "X['cur_run_rate'] = X['cur_run_rate'].apply(lambda x: 0 if x <= 0 or np.isinf(x) else x)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Batting_team', 'Bowling_team', 'city']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and testing (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=45)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=45)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [200],\n",
    "#     'max_depth': [10],\n",
    "#     'min_samples_split': [2],\n",
    "#     'min_samples_leaf': [2]\n",
    "# }\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'Validation Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# Perform grid search over all parameter combinations\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            for min_samples_leaf in param_grid['min_samples_leaf']:\n",
    "                # Create and train the RandomForestClassifier\n",
    "                clf12 = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                            random_state=45)\n",
    "                clf12.fit(X_train, y_train)\n",
    "                \n",
    "                # Make predictions on the validation set\n",
    "                validate_pred = clf12.predict(X_validate)\n",
    "                accuracy_validate = accuracy_score(y_validate, validate_pred)\n",
    "                \n",
    "                # Make predictions on the test set\n",
    "                test_pred = clf12.predict(X_test)\n",
    "                accuracy_test = accuracy_score(y_test, test_pred)\n",
    "                \n",
    "                # Create a DataFrame with the current result\n",
    "                current_result = pd.DataFrame({\n",
    "                    'n_estimators': [n_estimators],\n",
    "                    'max_depth': [max_depth],\n",
    "                    'min_samples_split': [min_samples_split],\n",
    "                    'min_samples_leaf': [min_samples_leaf],\n",
    "                    'Validation Accuracy': [accuracy_validate],\n",
    "                    'Test Accuracy': [accuracy_test]\n",
    "                })\n",
    "                \n",
    "                # Concatenate the current result with the results DataFrame\n",
    "                results_df = pd.concat([results_df, current_result], ignore_index=True)\n",
    "                \n",
    "                # Print the results DataFrame\n",
    "                print(results_df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-18T09:29:42.686959800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
