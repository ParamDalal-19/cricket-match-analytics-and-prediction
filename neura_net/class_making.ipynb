{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data from the Excel file\n",
    "df = pd.read_excel('neuralnet_data.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T17:34:12.855489700Z",
     "start_time": "2023-10-20T17:33:58.802073900Z"
    }
   },
   "id": "a97d2ee9a240da6e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T17:34:17.073598700Z",
     "start_time": "2023-10-20T17:34:17.073094400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define your custom function to map strike_rate to strike_class\n",
    "def classify_high_score(high_score):\n",
    "    if high_score == \"teju\":\n",
    "        return 0\n",
    "    elif 0 <= int(high_score) <= 30:\n",
    "        return 1\n",
    "    elif 31 <= int(high_score) <= 60:\n",
    "        return 2\n",
    "    elif 61 <= int(high_score) <= 90:\n",
    "        return 3\n",
    "    elif 91 <= int(high_score) <= 120:\n",
    "        return 4\n",
    "    elif 121 <= int(high_score) <= 150:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6  \n",
    "\n",
    "def classify_not_out(not_out):\n",
    "    if not_out == \"teju\":\n",
    "        return 0\n",
    "    elif 0 <= int(not_out) <= 30:\n",
    "        return 1\n",
    "    elif 31 <= int(not_out) <= 60:\n",
    "        return 2\n",
    "    elif 61 <= int(not_out) <= 90:\n",
    "        return 3\n",
    "    elif 91 <= int(not_out) <= 120:\n",
    "        return 4\n",
    "    elif 121 <= int(not_out) <= 150:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Apply the custom function to create the \"strike_class\" column\n",
    "\n",
    "df['high_score_class'] = df['Highest Score'].apply(classify_high_score)\n",
    "df['not_out_class'] = df['Total Not Outs'].apply(classify_not_out)\n",
    "# Save the DataFrame back to an Excel file if needed\n",
    "df.to_excel('new_neuralnet.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T17:34:56.143187900Z",
     "start_time": "2023-10-20T17:34:21.484598100Z"
    }
   },
   "id": "37ab1e5507dfe5b8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 777.7919 - val_loss: 586.9716\n",
      "Epoch 2/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 579.1050 - val_loss: 576.9991\n",
      "Epoch 3/20\n",
      "4877/4877 [==============================] - 10s 2ms/step - loss: 573.8023 - val_loss: 573.8998\n",
      "Epoch 4/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 572.1382 - val_loss: 572.7570\n",
      "Epoch 5/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 571.2668 - val_loss: 572.5950\n",
      "Epoch 6/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 570.7665 - val_loss: 571.5563\n",
      "Epoch 7/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 570.4105 - val_loss: 571.2820\n",
      "Epoch 8/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 570.1492 - val_loss: 571.0085\n",
      "Epoch 9/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.9449 - val_loss: 572.0981\n",
      "Epoch 10/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.8292 - val_loss: 570.6962\n",
      "Epoch 11/20\n",
      "4877/4877 [==============================] - 10s 2ms/step - loss: 569.7427 - val_loss: 570.4611\n",
      "Epoch 12/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.5925 - val_loss: 570.5593\n",
      "Epoch 13/20\n",
      "4877/4877 [==============================] - 10s 2ms/step - loss: 569.6119 - val_loss: 570.4815\n",
      "Epoch 14/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.5408 - val_loss: 570.3052\n",
      "Epoch 15/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.5207 - val_loss: 570.5066\n",
      "Epoch 16/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.4226 - val_loss: 570.7664\n",
      "Epoch 17/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.4778 - val_loss: 570.9409\n",
      "Epoch 18/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.4237 - val_loss: 571.0139\n",
      "Epoch 19/20\n",
      "4877/4877 [==============================] - 10s 2ms/step - loss: 569.3878 - val_loss: 570.1632\n",
      "Epoch 20/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.3464 - val_loss: 570.5930\n",
      "1524/1524 [==============================] - 2s 1ms/step\n",
      "Mean Squared Error: 579.3832449006993\n",
      "R-squared: 0.14665933999763825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your data from the Excel file\n",
    "data = pd.read_excel('new_neuralnet.xlsx')\n",
    "\n",
    "# Define the features and the target variable\n",
    "X = data[['Over', 'Delivery', 'high_score_class', 'strike_class', 'not_out_class']]\n",
    "y = data['total_run_batter']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Build a simple neural network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(5, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(1)  # Output layer with a single unit for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:03:11.681614Z",
     "start_time": "2023-10-18T13:59:40.099087400Z"
    }
   },
   "id": "8ef8a2e5af0cfff9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Load your data from the Excel file\n",
    "data1 = pd.read_excel('final_result.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T14:12:35.319151400Z",
     "start_time": "2023-10-17T14:12:24.113763100Z"
    }
   },
   "id": "c3637d8f34d412ab"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7620/7620 [==============================] - 8s 984us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model\n",
    "predictions = model.predict(data1)\n",
    "\n",
    "# Add the predictions as a new column to the DataFrame\n",
    "data1['Predicted_total_run_batter'] = predictions\n",
    "\n",
    "# Save the DataFrame with predictions to a new Excel file\n",
    "data1.to_excel('final_result.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T14:13:12.373391Z",
     "start_time": "2023-10-17T14:12:36.357552600Z"
    }
   },
   "id": "6c8a9007093fb688"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights associated with the inputs:\n",
      "[[ 0.9110675  -0.03449272  1.0922453   0.6379537  -0.6832345 ]\n",
      " [ 0.34656823 -0.7189315   0.26758012  0.02426003 -0.70526344]\n",
      " [-1.5374088   0.046777    1.6355581  -1.8444831  -0.8660773 ]\n",
      " [ 0.4858154   0.07428534  0.6507748   0.7169861   0.3320721 ]\n",
      " [ 0.42746195  0.16714458  0.35787955  0.20249411  0.17194664]]\n"
     ]
    }
   ],
   "source": [
    "# Get the weights from the first dense layer\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Convert the weights to a NumPy array\n",
    "weights_array = np.array(weights)\n",
    "\n",
    "# Print the weights\n",
    "print(\"Weights associated with the inputs:\")\n",
    "print(weights_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:03:19.069761700Z",
     "start_time": "2023-10-18T14:03:19.043334400Z"
    }
   },
   "id": "bd505cce243bf7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights connecting the hidden layer to the output:\n",
      "[[-2.0390031 ]\n",
      " [-0.65763295]\n",
      " [ 2.231145  ]\n",
      " [-2.4533222 ]\n",
      " [ 0.27485844]]\n"
     ]
    }
   ],
   "source": [
    "# Get the weights from the output layer\n",
    "output_layer_weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "# Convert the weights to a NumPy array\n",
    "output_layer_weights_array = np.array(output_layer_weights)\n",
    "\n",
    "# Print the weights\n",
    "print(\"Weights connecting the hidden layer to the output:\")\n",
    "print(output_layer_weights_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T14:08:23.062179900Z",
     "start_time": "2023-10-18T14:08:22.968229200Z"
    }
   },
   "id": "d88f83b9fa7b5207"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 706.3303 - val_loss: 583.4330\n",
      "Epoch 2/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 576.5676 - val_loss: 575.1510\n",
      "Epoch 3/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 572.5237 - val_loss: 573.9145\n",
      "Epoch 4/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 571.2668 - val_loss: 572.5878\n",
      "Epoch 5/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 570.7267 - val_loss: 572.6152\n",
      "Epoch 6/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 570.3229 - val_loss: 571.2458\n",
      "Epoch 7/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 570.1104 - val_loss: 571.6794\n",
      "Epoch 8/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.9205 - val_loss: 572.4346\n",
      "Epoch 9/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.8746 - val_loss: 570.7436\n",
      "Epoch 10/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.7186 - val_loss: 570.5873\n",
      "Epoch 11/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.7788 - val_loss: 570.7797\n",
      "Epoch 12/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.6245 - val_loss: 573.4692\n",
      "Epoch 13/20\n",
      "4877/4877 [==============================] - 10s 2ms/step - loss: 569.6064 - val_loss: 570.9509\n",
      "Epoch 14/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.5068 - val_loss: 571.5267\n",
      "Epoch 15/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.6934 - val_loss: 570.4311\n",
      "Epoch 16/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.4963 - val_loss: 570.7216\n",
      "Epoch 17/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.4944 - val_loss: 570.4922\n",
      "Epoch 18/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.4026 - val_loss: 570.4806\n",
      "Epoch 19/20\n",
      "4877/4877 [==============================] - 9s 2ms/step - loss: 569.4518 - val_loss: 570.2571\n",
      "Epoch 20/20\n",
      "4877/4877 [==============================] - 8s 2ms/step - loss: 569.4707 - val_loss: 570.3471\n",
      "1524/1524 [==============================] - 2s 1ms/step\n",
      "Mean Squared Error: 579.4386582905424\n",
      "R-squared: 0.1465777247644091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle  # Import the pickle library\n",
    "\n",
    "# Load your data from the Excel file\n",
    "data = pd.read_excel('new_neuralnet.xlsx')\n",
    "\n",
    "# Define the features and the target variable\n",
    "X = data[['Over', 'Delivery', 'high_score_class', 'strike_class', 'not_out_class']]\n",
    "y = data['total_run_batter']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple neural network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(5, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(1)  # Output layer with a single unit for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open('neural_network_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T17:39:00.382554600Z",
     "start_time": "2023-10-20T17:35:44.293783900Z"
    }
   },
   "id": "581fb3402aea736b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load the trained model from the pickle file\n",
    "with open('neural_network_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:04:21.648506Z",
     "start_time": "2023-10-20T19:04:21.538586200Z"
    }
   },
   "id": "1dbe8b5e20a3b9a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({'Over': [1], 'Delivery': [3], 'high_score_class': [1], 'strike_class': [4], 'not_out_class': [4]})\n",
    "predictions = loaded_model.predict(new_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:07:26.030681700Z",
     "start_time": "2023-10-20T19:07:25.958656400Z"
    }
   },
   "id": "ae090cc953dd60e8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[20.700699]], dtype=float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:07:26.991842800Z",
     "start_time": "2023-10-20T19:07:26.980577200Z"
    }
   },
   "id": "772f2fc8640d313c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a10c1fd28d8d8b63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
